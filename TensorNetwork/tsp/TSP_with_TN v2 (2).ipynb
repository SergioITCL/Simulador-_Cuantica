{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travelling Salesman Problem with Tensor Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a implementar el TSP con tensor networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorkrowch as tk\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Función global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSP_solver(distances:np.array, tau:float=1, verbose:bool=True, n_layers:int=1):\n",
    "    \"\"\"\n",
    "    Solves the TSP using tensor networks.\n",
    "    Parameters:\n",
    "        distances (np.array): Array of distances between cities.\n",
    "        tau (float): Imaginary time parameter.\n",
    "    Returns:\n",
    "        list: List of cities in the optimal path.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Numero de ciudades\n",
    "    N_cities = distances.shape[0]\n",
    "    remaining_cities = np.arange(N_cities - 1)\n",
    "\n",
    "    if verbose:\n",
    "        out = display(progress(0, N_cities), display_id=True)\n",
    "        var_counter = 0\n",
    "\n",
    "    #Vector solución\n",
    "    solution = np.zeros(N_cities, dtype=int)\n",
    "    solution[0] = N_cities - 1\n",
    "\n",
    "    if verbose:\n",
    "        var_counter += 1\n",
    "        out.update(progress(var_counter, N_cities))\n",
    "    \n",
    "\n",
    "\n",
    "    for t in range(1, N_cities-1):\n",
    "        new_distances = np.ones((N_cities - t + 2, N_cities - t + 2), dtype=float)*np.inf\n",
    "        for i, city_origen in enumerate(remaining_cities):\n",
    "            for j, city_destino in enumerate(remaining_cities):\n",
    "                new_distances[i, j] = distances[city_origen, city_destino]\n",
    "            \n",
    "            new_distances[i, -1] = distances[city_origen, -1]\n",
    "        \n",
    "        for j, city_destino in enumerate(remaining_cities):\n",
    "            new_distances[-2, j] = distances[solution[t-1], city_destino]\n",
    "        \n",
    "        if t != 1: new_distances[-2, -1] = distances[solution[t-1], -1]\n",
    "\n",
    "        # Obtenemos la solución parcial con el mapeado impuesto al grafo recortado\n",
    "        vector_solution = TSP_solver_from_to(new_distances, tau, n_layers)\n",
    "\n",
    "        if max(vector_solution) < 1e-120: break\n",
    "        \n",
    "        # Obtener la solución\n",
    "        partial_solution = np.argmax(vector_solution)\n",
    "\n",
    "        # Mapeamos la solución parcial a la solución global\n",
    "        solution[t] = remaining_cities[partial_solution]\n",
    "\n",
    "        # Actualizamos el vector de ciudades restantes\n",
    "        remaining_cities = np.delete(remaining_cities, partial_solution)\n",
    "        \n",
    "        if verbose:\n",
    "            var_counter += 1\n",
    "            out.update(progress(var_counter, N_cities))\n",
    "\n",
    "    # Último paso\n",
    "    solution[-1] = remaining_cities[0]\n",
    "    if verbose:\n",
    "        var_counter += 1\n",
    "        out.update(progress(var_counter, N_cities))\n",
    "\n",
    "    return solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función TSP desde uno inicial a uno final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSP_solver_from_to(distances:np.array, tau:float, n_layers:int):\n",
    "\n",
    "    # Crear la tensor network\n",
    "    tn = tk.TensorNetwork(name='TSP')\n",
    "\n",
    "    # Creamos los tensores\n",
    "    tensor_network = create_tensors(tn, distances, tau, n_layers)\n",
    "\n",
    "    # Contracción de la tensor network\n",
    "    vector_solution = contract_tensors(tensor_network)\n",
    "\n",
    "    return vector_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Función de Tensor Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función creadora de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensors(tn:tk.TensorNetwork, distances:np.array, tau:float, n_layers:int):\n",
    "    # Numero de nodos en el subproblema\n",
    "    n_nodes = len(distances)-2\n",
    "    # Capa de inicialización\n",
    "    s_layer = superposition_layer(tn, n_nodes)\n",
    "\n",
    "    # Capa de evolución en tiempo imaginario\n",
    "    e_layer = evolution_layer(tn, n_nodes, distances, tau)\n",
    "\n",
    "    # Capa de restricción\n",
    "    r_layer = []\n",
    "    append = r_layer.append\n",
    "    if n_layers >= n_nodes-1:\n",
    "        for node in range(n_nodes-1):\n",
    "            append( restriction_layer(tn, n_nodes, node))\n",
    "    else:\n",
    "        condition_index = np.arange(n_nodes-1)\n",
    "        for _ in range(n_layers):\n",
    "            node = np.random.choice(condition_index)\n",
    "            append( restriction_layer(tn, n_nodes, node))\n",
    "            condition_index = np.delete(condition_index, np.where(condition_index == node))\n",
    "\n",
    "    #Capa de traceado\n",
    "    t_layer = trace_layer(tn, n_nodes)\n",
    "\n",
    "    for node in range(n_nodes):\n",
    "        s_layer[node]['right'] ^ e_layer[node]['left']\n",
    "        if n_layers != 0:\n",
    "            e_layer[node]['right'] ^ r_layer[0][node]['left']\n",
    "            for depth in range(min(n_nodes-2,n_layers-1)):\n",
    "                r_layer[depth][node]['right'] ^ r_layer[depth+1][node]['left']\n",
    "            r_layer[-1][node]['right'] ^ t_layer[node]['left']\n",
    "        else:\n",
    "            e_layer[node]['right'] ^ t_layer[node]['left']\n",
    "\n",
    "    if n_layers == 0:\n",
    "        return [s_layer, e_layer, t_layer]\n",
    "    \n",
    "    return [s_layer, e_layer] + r_layer + [t_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capa de superposición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superposition_layer(tn:tk.TensorNetwork, n_nodes:int):\n",
    "\n",
    "    uniform_node = tk.Node(tensor=torch.ones(n_nodes), name='uniform', axes_names=['right'], network=tn, virtual=True)\n",
    "\n",
    "    layer = []\n",
    "    append = layer.append\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        append(   tk.Node(shape=(n_nodes,), name=f'initial_({i},{0})', axes_names=['right'], network=tn)     )\n",
    "        layer[i].set_tensor_from(uniform_node)\n",
    "\n",
    "    #stack_nodes = tk.stack(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capa de evolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolution_layer(tn: tk.TensorNetwork, n_nodes:int, distances:np.array, tau:float):\n",
    "    # Inicializamos la lista que contendrá los nodos de la capa de evolución\n",
    "    layer = []\n",
    "    append = layer.append\n",
    "\n",
    "    # Creamos el tensor para el nodo inicial\n",
    "    initial_tensor = torch.zeros(size=(n_nodes, n_nodes, n_nodes))\n",
    "    for current in range(n_nodes):\n",
    "        # Calculamos la exponencial negativa de la distancia multiplicada por tau\n",
    "        initial_tensor[current, current, current] = np.exp(-tau*distances[n_nodes,current])\n",
    "    # Creamos el nodo inicial y lo añadimos a la capa\n",
    "    initial_node = tk.Node(tensor=initial_tensor, name=f'evolution_({0},{1})', network=tn, axes_names=['left', 'right', 'down'])\n",
    "    append(initial_node)\n",
    "\n",
    "    # Creamos el tensor para los nodos intermedios\n",
    "    intermediate_tensor = torch.zeros(size=(n_nodes, n_nodes, n_nodes, n_nodes))\n",
    "    for previous in range(n_nodes):\n",
    "        for current in range(n_nodes):\n",
    "            # Calculamos la exponencial negativa de la distancia multiplicada por tau\n",
    "            intermediate_tensor[current, current, previous, current] = np.exp(-tau*distances[previous,current])\n",
    "    # Creamos un nodo virtual con el tensor intermedio\n",
    "    intermediate_node = tk.Node(tensor=intermediate_tensor, name=f'evolution_(uniform)', network=tn, virtual=True)\n",
    "\n",
    "    # Creamos los nodos intermedios y los añadimos a la capa\n",
    "    for node in range(1, n_nodes-1):\n",
    "        append(  tk.Node(shape=(n_nodes, n_nodes, n_nodes, n_nodes), name=f'evolution_({node},{1})', network=tn, axes_names=['left', 'right', 'up', 'down'])   )\n",
    "        layer[node].set_tensor_from(intermediate_node)\n",
    "\n",
    "        layer[node]['up'] ^ layer[node-1]['down']\n",
    "\n",
    "    # Creamos el tensor para el nodo final\n",
    "    final_tensor = torch.zeros(size=(n_nodes, n_nodes, n_nodes))\n",
    "    for previous in range(n_nodes):\n",
    "        for current in range(n_nodes):\n",
    "            # Calculamos la exponencial negativa de la suma de distancias multiplicada por tau\n",
    "            final_tensor[current, current, previous] = np.exp(-tau*(distances[previous,current]+distances[current, n_nodes+1]))\n",
    "    # Creamos el nodo final y lo añadimos a la capa\n",
    "    final_node = tk.Node(tensor=final_tensor, name=f'evolution_({n_nodes-1},{1})', network=tn, axes_names=['left', 'right', 'up'])\n",
    "    append(final_node)\n",
    "    \n",
    "    layer[-1]['up'] ^ layer[-2]['down']\n",
    "\n",
    "    # Apilamos todos los nodos de la capa\n",
    "    #stack_nodes = tk.stack(layer)\n",
    "\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capas de restricción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restriction_layer(tn:tk.TensorNetwork, n_nodes:int, node:int):\n",
    "    # Inicializamos la lista que contendrá los nodos de la capa de restricción\n",
    "    layer = []\n",
    "    append = layer.append\n",
    "\n",
    "    # Creamos el tensor para el nodo inicial\n",
    "    initial_tensor = torch.zeros(size=(n_nodes, n_nodes, 2))\n",
    "    for current in range(n_nodes):\n",
    "        if current == node: initial_tensor[node, node, 1] = 1\n",
    "        else:               initial_tensor[current, current, 0] = 1\n",
    "    \n",
    "    # Creamos el nodo inicial y lo añadimos a la capa\n",
    "    initial_node = tk.Node(tensor=initial_tensor, name=f'restr_({node},{0})', network=tn, axes_names=['left', 'right', 'down'])\n",
    "    append(initial_node)\n",
    "\n",
    "    # Creamos el tensor para los nodos intermedios\n",
    "    intermediate_tensor = torch.zeros(size=(n_nodes, n_nodes, 2, 2))\n",
    "    for current in range(n_nodes):\n",
    "        if current == node:\n",
    "            intermediate_tensor[current, current, 0, 1] = 1\n",
    "        else:\n",
    "            intermediate_tensor[current, current, 0, 0] = 1\n",
    "            intermediate_tensor[current, current, 1, 1] = 1\n",
    "    \n",
    "    # Creamos un nodo virtual con el tensor intermedio\n",
    "    intermediate_node = tk.Node(tensor=intermediate_tensor, name=f'restr_(uniform)', network=tn, virtual=True)\n",
    "\n",
    "    # Creamos los nodos intermedios y los añadimos a la capa\n",
    "    for i_node in range(1, n_nodes-1):\n",
    "        append(  tk.Node(shape=(n_nodes, n_nodes, 2, 2), name=f'restr_({node},{i_node})', network=tn, axes_names=['left', 'right', 'up', 'down'])   )\n",
    "        layer[i_node].set_tensor_from(intermediate_node)\n",
    "\n",
    "        layer[i_node]['up'] ^ layer[i_node-1]['down']\n",
    "\n",
    "    # Creamos el tensor para el nodo final\n",
    "    final_tensor = torch.zeros(size=(n_nodes, n_nodes, 2))\n",
    "    for current in range(n_nodes):\n",
    "        if current == node: final_tensor[current, current, 0] = 1\n",
    "        else:               final_tensor[current, current, 1] = 1\n",
    "\n",
    "    # Creamos el nodo final y lo añadimos a la capa\n",
    "    final_node = tk.Node(tensor=final_tensor, name=f'restr_({node},{n_nodes-1})', network=tn, axes_names=['left', 'right', 'up'])\n",
    "    append(final_node)\n",
    "    \n",
    "    layer[-1]['up'] ^ layer[-2]['down']\n",
    "\n",
    "    # Apilamos todos los nodos de la capa\n",
    "    #stack_nodes = tk.stack(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capa de traceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_layer(tn:tk.TensorNetwork, n_nodes:int):\n",
    "\n",
    "    uniform_node = tk.Node(tensor=torch.ones(n_nodes), name='uniform', axes_names=['left'], network=tn, virtual=True)\n",
    "\n",
    "    layer = []\n",
    "    append = layer.append\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        append(   tk.Node(shape=(n_nodes,), name=f'trace_({i})', axes_names=['left'], network=tn)     )\n",
    "        layer[i].set_tensor_from(uniform_node)\n",
    "\n",
    "    #stack_nodes = tk.stack(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de contracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_tensors(tensor_network:list[list[tk.Node]]):\n",
    "    # Contraemos la capa de superposición con la capa de evolución´\n",
    "    n_qudits = len(tensor_network[0])\n",
    "    depth = len(tensor_network)\n",
    "    # Extremos\n",
    "    for qudit in range(n_qudits):\n",
    "        tensor_network[1][qudit] = tk.contract_between_(tensor_network[0][qudit], tensor_network[1][qudit])\n",
    "        tensor_network[1][qudit].name = f'Initial_evolution_({qudit})'\n",
    "\n",
    "        if qudit != 0:\n",
    "            tensor_network[-2][qudit] = tk.contract_between_(tensor_network[-1][qudit], tensor_network[-2][qudit])\n",
    "            tensor_network[-2][qudit].name = f'trace_restr_({qudit})'\n",
    "    \n",
    "    # Contraccion de ultimo qudit\n",
    "    result = tensor_network[-2][-1]\n",
    "    \n",
    "    for layer in range(depth-3, 0, -1):\n",
    "        result = tk.contract_between_(result, tensor_network[layer][-1])\n",
    "\n",
    "    # Contraccion de los demas qudits\n",
    "    for qudit in range(n_qudits-2, -1, -1):\n",
    "        for layer in range(1, depth-1):\n",
    "            result = tk.contract_between_(result, tensor_network[layer][qudit])\n",
    "\n",
    "    return result.tensor.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Funciones del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_problem(n_cities:int, n_conexions:int, distance_range:float):\n",
    "    distances = torch.ones(size=(n_cities, n_cities), dtype=int)*np.inf\n",
    "\n",
    "    for previous in range(n_cities):\n",
    "        possible_destinies = np.delete(np.arange(n_cities, dtype=int), previous)\n",
    "\n",
    "        for destiny in range(n_conexions):\n",
    "            current = np.random.choice(possible_destinies)\n",
    "            distances[previous, current] = np.random.randint(1,distance_range)\n",
    "            possible_destinies = np.delete(possible_destinies, np.where(possible_destinies == current))\n",
    "\n",
    "    return distances\n",
    "\n",
    "def cost_solution(solution:np.array, distances:np.array):\n",
    "    cost = 0\n",
    "    for i in range(len(solution)-1):\n",
    "        cost += distances[solution[i], solution[i+1]]\n",
    "\n",
    "    cost += distances[solution[-1], solution[0]]\n",
    "\n",
    "    return cost\n",
    "\n",
    "def progress(value, max=100):\n",
    "    return HTML(\"\"\"\n",
    "                <progress\n",
    "                value='{value}'\n",
    "                max='{max}'\n",
    "                style='width: 50%'\n",
    "                >\n",
    "                {value}\n",
    "                </progress>\n",
    "                <p> Progreso: {porc} %</p>\n",
    "                \"\"\".format(value=value, max=max, porc=np.round(value/max*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "\n",
    "def create_data_model(distances, n_cities):\n",
    "    \"\"\"Stores the data for the problem.\"\"\"\n",
    "    data = {}\n",
    "    data[\"distance_matrix\"] = [[ int(_.numpy().flatten()[0]) if _ < np.inf else 30000 for _ in origin_list] for origin_list in distances]\n",
    "    data[\"num_vehicles\"] = 1\n",
    "    data[\"depot\"] = n_cities - 1\n",
    "    return data\n",
    "\n",
    "\n",
    "def print_solution(manager, routing, solution, distances):\n",
    "    \"\"\"Prints solution on console.\"\"\"\n",
    "    print(f\"Objective: {solution.ObjectiveValue()} miles\")\n",
    "    index = routing.Start(0)\n",
    "    plan_output = \"Route for vehicle 0:\\n\"\n",
    "    route_distance = 0\n",
    "    route = [index]\n",
    "    while not routing.IsEnd(index):\n",
    "        plan_output += f\" {manager.IndexToNode(index)} ->\"\n",
    "        previous_index = index\n",
    "        index = solution.Value(routing.NextVar(index))\n",
    "        route.append(index)\n",
    "        route_distance += routing.GetArcCostForVehicle(previous_index, index, 0)\n",
    "    plan_output += f\" {manager.IndexToNode(index)}\\n\"\n",
    "    print(plan_output)\n",
    "    plan_output += f\"Route distance: {route_distance}miles\\n\"\n",
    "    print(route[:-1])\n",
    "    print(chr(27)+\"[1;33m\"+'Coste: '+str(cost_solution(route[:-1], distances)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def solucion_Google(distances, n_cities):\n",
    "    \"\"\"Simple Travelling Salesperson Problem (TSP) between cities.\"\"\"\n",
    "    \"\"\"Entry point of the program.\"\"\"\n",
    "    # Instantiate the data problem.\n",
    "    data = create_data_model(distances, n_cities)\n",
    "\n",
    "    # Create the routing index manager.\n",
    "    manager = pywrapcp.RoutingIndexManager(\n",
    "        len(data[\"distance_matrix\"]), data[\"num_vehicles\"], data[\"depot\"]\n",
    "    )\n",
    "    def distance_callback(from_index, to_index):\n",
    "        \"\"\"Returns the distance between the two nodes.\"\"\"\n",
    "        # Convert from routing variable Index to distance matrix NodeIndex.\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        return data[\"distance_matrix\"][from_node][to_node]\n",
    "\n",
    "    # Create Routing Model.\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "\n",
    "    \n",
    "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
    "\n",
    "    # Define cost of each arc.\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "\n",
    "    # Setting first solution heuristic.\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = (\n",
    "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
    "    )\n",
    "\n",
    "    # Solve the problem.\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "    # Print solution on console.\n",
    "    if solution:\n",
    "        print_solution(manager, routing, solution, distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <progress\n",
       "                value='10'\n",
       "                max='10'\n",
       "                style='width: 50%'\n",
       "                >\n",
       "                10\n",
       "                </progress>\n",
       "                <p> Progreso: 100.0 %</p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solucion:  [9 7 6 3 0 8 4 2 1 5]\n",
      "\u001b[1;33mCoste de solucion: tensor(27.)\n",
      "====================================================================================================\n",
      "Objective: 32 miles\n",
      "Route for vehicle 0:\n",
      " 9 -> 8 -> 2 -> 4 -> 5 -> 0 -> 3 -> 7 -> 6 -> 1 -> 9\n",
      "\n",
      "[9, 8, 2, 4, 5, 0, 3, 7, 6, 1]\n",
      "\u001b[1;33mCoste: tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "n_cities = 10\n",
    "n_conexions = 5\n",
    "distance_range = 10\n",
    "tau = 1e0\n",
    "n_layers = 11\n",
    "\n",
    "distances = generate_problem(n_cities, n_conexions, distance_range)\n",
    "\n",
    "solution = TSP_solver(distances, tau=tau, n_layers=n_layers)\n",
    "\n",
    "print('Solucion: ', solution)\n",
    "print(chr(27)+\"[1;33m\"+'Coste de solucion: '+str(cost_solution(solution, distances)))\n",
    "\n",
    "print('='*100)\n",
    "solucion_Google(distances, n_cities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "activate = False\n",
    "\n",
    "# Advertencia: Este programa demuestra que P ≠ NP, no que P = NP\n",
    "if activate:\n",
    "    import itertools\n",
    "\n",
    "    def tsp_fuerza_bruta(distancias):\n",
    "        n = len(distancias)\n",
    "        ciudades = range(n)\n",
    "        mejor_ruta = None\n",
    "        mejor_distancia = float('inf')\n",
    "        \n",
    "        for permutacion in itertools.permutations(ciudades[1:]):\n",
    "            ruta = (0,) + permutacion + (0,)\n",
    "            distancia_total = sum(distancias[ruta[i]][ruta[i+1]] for i in range(n))\n",
    "            \n",
    "            if distancia_total < mejor_distancia:\n",
    "                mejor_distancia = distancia_total\n",
    "                mejor_ruta = ruta\n",
    "        \n",
    "        return mejor_ruta[:-1], mejor_distancia\n",
    "\n",
    "    # Usar la función\n",
    "    solucion_optima, distancia_optima = tsp_fuerza_bruta(data[\"distance_matrix\"])\n",
    "\n",
    "    print(\"Solución óptima encontrada por fuerza bruta:\")\n",
    "    print(\"Ruta:\", solucion_optima)\n",
    "    print(\"Distancia total:\", distancia_optima)\n",
    "\n",
    "    # Nota: Este enfoque tiene una complejidad de O(n!), lo que demuestra que P ≠ NP\n",
    "    # para el problema del TSP, ya que no se conoce un algoritmo polinomial para resolverlo.\n",
    "\n",
    "    tsp_fuerza_bruta(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk.Node"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
