{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo que permite resolver problemas QUBO densos empleando Tensor Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a crear e implementar un algoritmo en tensor networks basado en el método de las señales y evolución en tiempo imaginario para resolver problemas QUBO. Utiliza un método de eliminación de capas de evolución para reducir la complejidad computacional.\n",
    "\n",
    "Versiones:\n",
    "\n",
    "- alpha 0: Implementación básica.\n",
    "- alpha 1: Añade el método de eliminación de capas.\n",
    "- alpha 2: Versión que va comprimiendo el MPS de derecha a izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorkrowch as tk\n",
    "import torch\n",
    "from quantum_sim.TensorNetwork.QUBO.qubo_core.qubo_solvers import  qubo_dimod_solver, recocido_simulado, random_qubo_solver\n",
    "from quantum_sim.TensorNetwork.QUBO.qubo_core.qubo_auxiliar_functions import evaluar_qubo, generar_matriz_qubo, matrix_QUBO_to_dict\n",
    "from quantum_sim.TensorNetwork.main.tensor_compresor import compresor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Funciones de la tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos los nodos de la Tensor Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_qubit(tn:tk.TensorNetwork, value,row):\n",
    "    if value == 0:\n",
    "        node = tk.Node(tensor = torch.tensor([1,0], dtype=torch.float64), network=tn, name = 'qudit_0', axes_names = ['right'])\n",
    "    elif value ==1:\n",
    "        node = tk.Node(tensor = torch.tensor([0,1], dtype=torch.float64), network=tn, name = 'qudit_1', axes_names = ['right'])\n",
    "    elif value ==2:\n",
    "        node = tk.Node(tensor = torch.tensor([1,1], dtype=torch.float64), network=tn, name = f'qudit_+{row}', axes_names = ['left'])\n",
    "    elif value ==3:\n",
    "        node = tk.Node(tensor = torch.tensor([1,-1], dtype=torch.float64), network=tn, name = 'qudit_-', axes_names = ['left'])\n",
    "    return node\n",
    "\n",
    "def node_Ai0(tn:tk.TensorNetwork, Q_element:float, qudit:int):\n",
    "    \"\"\"  \n",
    "    Nodos de superposicion con el termino diagonal.\n",
    "    \"\"\"\n",
    "    node = tk.Node(tensor = torch.tensor([1,Q_element], dtype=torch.float64), network=tn, name = f'qubit_({qudit})', axes_names = ['right'])\n",
    "    return node\n",
    "\n",
    "def node_A0i(tn:tk.TensorNetwork, qudit:int):\n",
    "    \"\"\"\n",
    "    Nodos de control.\n",
    "    \"\"\"\n",
    "    tensor = torch.zeros((2,2,2), dtype = torch.float64)\n",
    "    for i in range(0,2):\n",
    "        j=i; k=i\n",
    "        tensor[i,j,k]= 1\n",
    "    node = tk.Node(tensor = tensor, network=tn, name = f'A_({qudit},{qudit+1})', axes_names = ['left','right','down'])\n",
    "    return node\n",
    "\n",
    "def node_Aii(tn:tk.TensorNetwork, Q_element:float, row:int, column:int):\n",
    "    \"\"\"\n",
    "    Nodos de evolucion.\n",
    "    \"\"\"\n",
    "    tensor = torch.zeros((2,2,2,2), dtype = torch.float64)\n",
    "    for k in range(0,2):\n",
    "        for i in range(0,2):\n",
    "            l=k; j=i\n",
    "            if k*i == 1:\n",
    "                tensor[i,j,k,l] = Q_element\n",
    "            else:\n",
    "                tensor[i,j,k,l] = 1\n",
    "    node = tk.Node(tensor = tensor, network = tn, name = f'A_({row},{column})', axes_names=['left','right','up','down'])\n",
    "    return node\n",
    "\n",
    "def node_Afi(tn:tk.TensorNetwork, Q_element:float, column,max_element):\n",
    "    \"\"\"\n",
    "    Nodo final de evolucion.\n",
    "    \"\"\"\n",
    "    tensor = torch.zeros((2,2,2), dtype = torch.float64)\n",
    "    for k in range(2):\n",
    "        for i in range(2):\n",
    "            j=i\n",
    "            if k*i == 1:\n",
    "                tensor[i,j,k] = Q_element\n",
    "            else:\n",
    "                tensor[i,j,k] = 1\n",
    "\n",
    "    node = tk.Node(tensor=tensor, network=tn, name = f'A_({max_element-1},{column})',axes_names=['left','right','up'])\n",
    "    return node\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de la Tensor Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_network_generator(Q_matrix:np.array, tau:float)->list[list[tk.Node]]:\n",
    "    \"\"\"   \n",
    "    Args:\n",
    "\n",
    "    Return:\n",
    "\n",
    "    \"\"\"\n",
    "    # Inicializamos la tensor network\n",
    "    n_variables  = len(Q_matrix[0])\n",
    "    network      = tk.TensorNetwork('QUBO_TN')\n",
    "    tensor_network_matrix = [[None] * min(row+1+2, n_variables+2-1) for row in range(n_variables)]\n",
    "\n",
    "    # Exponencial de Q elementwise\n",
    "    Q_exponential = np.exp(-tau*Q_matrix)\n",
    "\n",
    "    # Capa de superposicion inicial\n",
    "    for row in range(n_variables):\n",
    "        tensor_network_matrix[row][0] = node_Ai0(network, Q_exponential[row][row], row)\n",
    "\n",
    "    # Capas de evolucion\n",
    "    for column in range(1, n_variables):\n",
    "        # Primer nodo\n",
    "        tensor_network_matrix[column-1][column] = node_A0i(network, column-1)\n",
    "\n",
    "        # Nodos intermedios\n",
    "        for row in range(column,n_variables-1):\n",
    "            tensor_network_matrix[row][column] = node_Aii(network, Q_exponential[row][column-1], row, column)\n",
    "        \n",
    "        # Ultimo nodo\n",
    "        tensor_network_matrix[n_variables-1][column] = node_Afi(network, Q_exponential[n_variables-1][column-1], column, n_variables)\n",
    "\n",
    "    # Capa de traceado\n",
    "    tensor_network_matrix[0][2] = node_qubit(network, 3, row)\n",
    "    for row in range(1, n_variables):\n",
    "        tensor_network_matrix[row][min(row+2, n_variables+2-2)] = node_qubit(network, 2, row)\n",
    "\n",
    "    return  tensor_network_matrix, network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexión y contracción de toda la Tensor Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mps_reshape(mps: list[tk.Node], network: tk.TensorNetwork) -> list[tk.Node]:\n",
    "     # Primer nodo\n",
    "     aux_mps = mps[0].tensor\n",
    "     aux_mps = torch.moveaxis(aux_mps, (0, 1, 2), (1, 0, 2))\n",
    "     aux_mps = torch.reshape(aux_mps, (1,aux_mps.shape[0], aux_mps.shape[1]*aux_mps.shape[2]))\n",
    "     network._remove_node(mps[0])\n",
    "     mps[0] = tk.Node(tensor = aux_mps, name = f'mps_({0})', axes_names = ['up', 'right', 'down'], network = network)\n",
    "\n",
    "     # Nodos intermedios\n",
    "     for column in range(1, len(mps)-1):\n",
    "          aux_mps = mps[column].tensor\n",
    "          aux_mps = torch.moveaxis(aux_mps, (0, 3, 2, 1, 4), (0, 1, 2, 3, 4))\n",
    "          aux_mps = torch.reshape(aux_mps, (aux_mps.shape[0]*aux_mps.shape[1],aux_mps.shape[2], aux_mps.shape[3]*aux_mps.shape[4]))\n",
    "          network._remove_node(mps[column])\n",
    "          mps[column] = tk.Node(tensor = aux_mps, name = f'mps_({column})', axes_names = ['up', 'right', 'down'], network = network)\n",
    "\n",
    "     # Final\n",
    "     aux_mps = mps[-1].tensor\n",
    "     aux_mps = torch.moveaxis(aux_mps, (0, 1, 2), (0, 2, 1))\n",
    "     aux_mps = torch.reshape(aux_mps, (aux_mps.shape[0]*aux_mps.shape[1], aux_mps.shape[2], 1))\n",
    "     network._remove_node(mps[-1])\n",
    "     mps[-1] = tk.Node(tensor = aux_mps, name = f'mps_({len(mps)-1})', axes_names = ['up', 'right', 'down'], network = network)\n",
    "     return mps\n",
    "\n",
    "def mps_desreshape(mps: list[tk.Node], network: tk.TensorNetwork) -> list[tk.Node]:\n",
    "     # Primer nodo\n",
    "     aux_mps = mps[0].tensor\n",
    "     aux_mps = torch.reshape(aux_mps, (2,aux_mps.shape[2]))\n",
    "     network._remove_node(mps[0])\n",
    "     mps[0] = tk.Node(tensor = aux_mps, name = f'mps_({0})', axes_names = ['right', 'down'], network = network)\n",
    "     \n",
    "     # Nodos intermedios\n",
    "     for column in range(1, len(mps)-1):\n",
    "          aux_mps = mps[column].tensor\n",
    "          aux_mps = torch.moveaxis(aux_mps, (0, 1, 2), (1, 0, 2))\n",
    "          #aux_mps = torch.reshape(aux_mps, (2, aux_mps.shape[0], aux_mps.shape[2]))\n",
    "          #aux_mps = torch.moveaxis(aux_mps, (0, 1, 2), (1, 0, 2))\n",
    "          network._remove_node(mps[column])\n",
    "          mps[column] = tk.Node(tensor = aux_mps, name = f'mps_({column})', axes_names = ['right','up', 'down'], network = network)   \n",
    "\n",
    "     # Nodo final\n",
    "     aux_mps = mps[-1].tensor\n",
    "     aux_mps = torch.reshape(aux_mps, (aux_mps.shape[0], aux_mps.shape[1]))\n",
    "     aux_mps = torch.moveaxis(aux_mps, (0, 1), (1, 0))\n",
    "     network._remove_node(mps[-1])\n",
    "     mps[-1] = tk.Node(tensor = aux_mps, name = f'mps_({len(mps)-1})', axes_names = ['right', 'up'], network = network)\n",
    "     return mps \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contraccion_arriba(mps: list[tk.Node], matrix_nodes:list[list[tk.Node]]):\n",
    "    mps[0]['right'] ^ matrix_nodes[0][2]['left']\n",
    "    mps[0]['down'] ^ mps[1]['up']\n",
    "    mps[0] = tk.contract_between_(mps[0], matrix_nodes[0][2])  \n",
    "    mps[1] = tk.contract_between_(mps[0], mps[1])  \n",
    "    matrix_nodes.pop(0)\n",
    "    return mps[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mps_contraction(tensor_network_matrix:list[list[tk.Node]], network, max_rank : int)->np.array:\n",
    "    \"\"\"\n",
    "    Funcion que contrae la tensor network de derecha a izquierda en formato de mps y va realizando la compresión según un cierto error relativo y un rango maximo.\n",
    "\n",
    "    Args:\n",
    "        matrix_nodes (list[list[tk.Node]]): _description_\n",
    "        etol (float): _description_\n",
    "        max_rank (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        np.array: _description_\n",
    "    \"\"\"\n",
    "    matrix_nodes = tensor_network_matrix.copy()\n",
    "    # Creamos el mps que se va a ir contrayendo de derecha a izquierda\n",
    "    mps = [row[0] for row in matrix_nodes]\n",
    "    # contraccion de la primera capa\n",
    "    for row in range(len(mps)):\n",
    "        \n",
    "        mps[row]['right'] ^ matrix_nodes[row][1]['left']\n",
    "        mps[row] = tk.contract_between_(mps[row], matrix_nodes[row][1])\n",
    "    mps = contraccion_arriba(mps, matrix_nodes)\n",
    "    # contraccion del resto de capas\n",
    "    for i in range(len(matrix_nodes[-1])-3):\n",
    "        # conexion y contracción vertical con la siguiente capa\n",
    "        for row in range(len(mps)):\n",
    "            if matrix_nodes[row][2] is not None:\n",
    "                mps[row]['right'] ^ matrix_nodes[row][2]['left']\n",
    "                mps[row] = tk.contract_between_(mps[row], matrix_nodes[row][2])\n",
    "        # Dar forma a los tensores externos de tensor-train\n",
    "        mps = mps_reshape(mps, network)\n",
    "        # Comprimir el mps para reducir la dimension de enlace.\n",
    "        mps = compresor(mps, max_rank)\n",
    "        # Devolver el tensor a la forma original\n",
    "        mps = mps_desreshape(mps, network)\n",
    "\n",
    "        #Eliminamos la primera columna de matrix_nodes\n",
    "        for row in range(len(mps)):\n",
    "            matrix_nodes[row].pop(0)\n",
    "        #Contraemos con el nodo resultante    \n",
    "        mps = contraccion_arriba(mps, matrix_nodes)\n",
    "    return np.dot(mps[0].tensor,np.ones(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Función general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la función que se encarga del proceso general. Se encarga del proceso de minimización resolviendo iterativamente cada una de las variables. Su proceso consiste en la creación de la tensor network, su contracción y la determinación de la variable a partir del vector resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubo_solver(Q_matrix:np.array, tau:float, max_rank:int)->np.array:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - Q_matrix: matriz de pesos del problema QUBO.\n",
    "    - tau: factor de amortiguamiento de la evolucion en tiempo imaginario.\n",
    "    \n",
    "    Return:\n",
    "    - solution: vector de solucion del problema.\n",
    "    \"\"\"\n",
    "    # Determinamos el tamaño del problema\n",
    "    n_variables = Q_matrix.shape[0]\n",
    "    solution = np.zeros(n_variables, dtype=int)\n",
    "    # Matrix QUBO auxiliar para las iteraciones\n",
    "    Q_matrix_aux = Q_matrix.copy()\n",
    "    # Generamos todos los tensores del problema\n",
    "    for variable  in range(n_variables-1):\n",
    "        \n",
    "        tensor_network_matrix, network = tensor_network_generator(Q_matrix_aux, tau)\n",
    "        #[[print(_,__,tensor_network_matrix[_][__]) for __ in range(len(tensor_network_matrix[_]))] for _ in range(len(tensor_network_matrix))]\n",
    "        result_vector = mps_contraction(tensor_network_matrix, network, max_rank)\n",
    "        if result_vector < 0:\n",
    "            solution[variable] = 1\n",
    "\n",
    "        if solution[variable] == 1:\n",
    "            for column in range(Q_matrix_aux.shape[1]):\n",
    "                Q_matrix_aux[column][column] += Q_matrix_aux[column][0]\n",
    "        # Borramos la primera fila y columna\n",
    "        Q_matrix_aux = Q_matrix_aux[1:,1:]\n",
    "    if Q_matrix_aux[0][0] < 0:\n",
    "        solution[-1] = 1\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación con un recocido simulado obtenido de ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_order(Q_matrix:np.array):\n",
    "    Q_matrix_aux = np.zeros(Q_matrix.shape, dtype=float)\n",
    "    list_of_sums = np.zeros(Q_matrix.shape[0])\n",
    "\n",
    "    Q_aux = Q_matrix + Q_matrix.T - np.diagonal(Q_matrix)\n",
    "    for row in range(Q_matrix.shape[0]):\n",
    "        list_of_sums[row] = sum(Q_aux[row])\n",
    "\n",
    "    indexes = np.argsort(list_of_sums)#[::-1]\n",
    "\n",
    "    for i in range(Q_matrix.shape[0]):\n",
    "        for j in range(Q_matrix.shape[1]):\n",
    "            Q_matrix_aux[i,j] = Q_matrix[indexes[i], indexes[j]]\n",
    "\n",
    "    return Q_matrix_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution TN:      [1 1 1 1 1]\n",
      "Coste de TN:      -1.7469565759717753\n",
      "Solution RS:      [1 1 1 1 1]\n",
      "Coste de RS:      -1.7469565759717753\n",
      "Coste de dimod iter:  -1.7469565759717753\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(31)\n",
    "n_variables =5\n",
    "n_diagonals = 5\n",
    "tau = 300\n",
    "max_rank = 400\n",
    "#number_layers = 5\n",
    "#for k in range(20):\n",
    "Q_matrix = generar_matriz_qubo(n_variables, n_diagonals)\n",
    "Q_matrix/= np.linalg.norm(Q_matrix)\n",
    "Q_matrix_dict = matrix_QUBO_to_dict(Q_matrix)\n",
    "#print(Q_matrix)\n",
    "# Inicial RS\n",
    "x_inicial = np.random.randint(2, size=n_variables)\n",
    "\n",
    "# TN\n",
    "solution = qubo_solver(Q_matrix, tau, max_rank)\n",
    "print('Solution TN:     ', str(solution))\n",
    "print('Coste de TN:     ', evaluar_qubo(Q_matrix, solution))\n",
    "\n",
    "\n",
    "# RS\n",
    "solution = recocido_simulado(Q_matrix, x_inicial, 10.0, 0.99, int(1e4))\n",
    "print('Solution RS:     ', str(solution))\n",
    "print('Coste de RS:     ', evaluar_qubo(Q_matrix, solution))\n",
    "'''\n",
    "# RS iterativo\n",
    "solution = qubo_solver_rs(Q_matrix, number_layers)\n",
    "#print('Solution RS iter: ', str(solution))\n",
    "print('Coste de RS iter: ', evaluar_qubo(Q_matrix, solution))\n",
    "'''\n",
    "# Dimod\n",
    "\n",
    "solution_dimod = qubo_dimod_solver(Q_matrix_dict, \"neal\")\n",
    "print('Coste de dimod iter: ', evaluar_qubo(Q_matrix, solution_dimod))\n",
    "\n",
    "best_c = random_qubo_solver(Q_matrix)\n",
    "print('Coste de Random: ', evaluar_qubo(Q_matrix, best_c))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
